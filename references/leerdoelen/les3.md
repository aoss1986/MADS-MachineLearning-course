Read chapter 6, 8 and 9. This is not about RNNs, but about the training process in general.  
It covers the training process (what we have been doing so far and will continue to do) and will give you a theoretical background on how the training process works and how to improve model performance, so in a sense all these chapters cover the more practical 3.15 from this lesson.  
However, it also helps with previous learning goals like:  
1.12, 2.8, 2.10 and it will also prepare you for 4.4, 4.5, 4.6  

# Les 3
De student begrijpt:  
3.1 - wat de motivatie is om RNNs te gebruiken  
3.2 - wat een window en horizon zijn  
3.3 - Wat belangrijk is bij datapreparatie om data leakage te voorkomen  
3.4 - Hoe een simple RNN werkt (hidden state)  
3.5 - Waarin een GRU en LSTM verschillen van RNN (gates)  
3.6 - Wat de functies van een gate zijn (remember, forget, something in between)  
3.7 - Hoe een gate werkt (met een hadamard product)  
3.8 - wat de voor en nadelen van een LSTM vs GRU vs RNN zijn  
3.9 - hoe windowing werkt bij timeseries, en waarom dat relevant is  
3.10 - hoe 1D convolutions werken bij timeseries  
3.11 - begrijpt hoe een naive model werkt en wat de motivatie hierachter is (MASE metric)  

De student kan:  
3.12 - passief de wiskunde van een RNN/GRU/LSTM volgen, inclusief de notatie  
3.13 - Een dataset windowen  
3.14 - Een configureerbare RNN bouwen  
3.15 - Een timeseries model handmatig hypertunen en daar verslaglegging van doen.  

# English
The student understands:

3.1 - What the motivation is to use RNNs  
3.2 - What a window and horizon are  
3.3 - What's important in data preparation to prevent data leakage  
3.4 - How a simple RNN works (hidden state)  
3.5 - How GRU and LSTM differ from RNN (gates)  
3.6 - What the functions of a gate are (remember, forget, something in between)  
3.7 - How a gate works (with a hadamard product)  
3.8 - What the advantages and disadvantages of LSTM vs GRU vs RNN are  
3.9 - How windowing works with timeseries, and why that's relevant  
3.10 - How 1D convolutions work with timeseries  
3.11 - Understands how a naive model works and the motivation behind it (MASE metric)  

The student can:  
3.12 - Passively follow the mathematics of RNN/GRU/LSTM, including the notation  
3.13 - Window a dataset  
3.14 - Build a configurable RNN  
3.15 - Manually hypertune a timeseries model and report on it  

# resources  
1. https://youtu.be/LHXXI4-IEns?si=JOgsNKCohksH0Pdf  
2. https://youtu.be/8HyCNIVRbSU?si=p8Su2AOJTRFFI5MK  
3. https://youtu.be/YCzL96nL7j0?si=42IUk3lm2ZzCTaLV  
4. https://youtu.be/WCUNPb-5EYI?si=lrHvh7-RsFthjjnD  

Watch the first two videos.  
The third video is from statsquest, if you like his style you can watch that one too.  
The last video explains the concept in a different way. If it confuses you, stick to the first three,
but if you feel like a different perspective might help, watch the last one too.  

The book doesnt cover RNNs, so all material comes from the lessons and the videos.  
